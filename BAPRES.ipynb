{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: protr\n",
      "\n",
      "R[write to console]: Loading required package: BiocGenerics\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'BiocGenerics'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:stats':\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which.max, which.min\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: S4Vectors\n",
      "\n",
      "R[write to console]: Loading required package: stats4\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'S4Vectors'\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from 'package:base':\n",
      "\n",
      "    expand.grid, I, unname\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: IRanges\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'IRanges'\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:grDevices':\n",
      "\n",
      "    windows\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: XVector\n",
      "\n",
      "R[write to console]: Loading required package: GenomeInfoDb\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: 'Biostrings'\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from 'package:base':\n",
      "\n",
      "    strsplit\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: RSQLite\n",
      "\n",
      "R[write to console]: Loading required package: parallel\n",
      "\n",
      "R[write to console]: Loading required package: e1071\n",
      "\n",
      "R[write to console]: Loading required package: caret\n",
      "\n",
      "R[write to console]: Loading required package: ggplot2\n",
      "\n",
      "R[write to console]: Loading required package: lattice\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "#start_time = time.time()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import rpy2\n",
    "from rpy2 import *\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import StrVector\n",
    "#from rpy2.robjects import FloatVector, r\n",
    "#from rpy2.robjects import globalenv\n",
    "from rpy2.robjects import numpy2ri\n",
    "#from rpy2.robjects.numpy2ri import numpy2ri\n",
    "from rpy2.robjects.packages import STAP\n",
    "#numpy2ri.activate()\n",
    "#from rpy2.robjects import pandas2ri\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import math\n",
    "import re\n",
    "import fileinput\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "#import tkFont\n",
    "# import filedialog module\n",
    "from tkinter import filedialog\n",
    "#from PIL import Image\n",
    "#from PIL import ImageTk\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di \n",
    "\n",
    "di.display_html('<script>jQuery(function() {if (jQuery(\"body.notebook_app\").length == 0) { jQuery(\".input_area\").toggle(); jQuery(\".prompt\").toggle();}});</script>', raw=True)\n",
    "\n",
    "di.display_html('''<button onclick=\"jQuery('.input_area').toggle(); jQuery('.prompt').toggle();\">Toggle code</button>''', raw=True)\n",
    "\n",
    "\n",
    "#generating 621D features\n",
    "\n",
    "def feature_extraction(file_name,svalue):\n",
    "    \n",
    "    fasta_file_name=file_name + \".fasta\"\n",
    "    lines = [line.rstrip('\\n') for line in open(fasta_file_name)]    \n",
    "    save_sequences= ''\n",
    "    sequences= []\n",
    "    sequences_name= []\n",
    "    for l in lines:\n",
    "        if(l == \"\"): #blank lines are disregarded\n",
    "                pass\n",
    "        elif (l[0] == '>'):\n",
    "            sequences_name.append(l[1:])\n",
    "            sequences.append(save_sequences)\n",
    "            save_sequences= ''\n",
    "        else:\n",
    "            save_sequences+= l\n",
    "\n",
    "    sequences.append(save_sequences)\n",
    "    del sequences[0]\n",
    "    \n",
    "    \n",
    "    all_generated_features=pd.DataFrame()\n",
    "    \n",
    "\n",
    "     \n",
    "    #amino acid composition\n",
    "    \n",
    "    def aa_composition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"AAC_BAC.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        aa_comp = r.extractAAC_BAC(seq)\n",
    "        return aa_comp\n",
    "    \n",
    "    #dipeptide composition\n",
    "    \n",
    "    def dc_composition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"DC_BAC.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        dc_comp = r.extractDC_BAC(seq)\n",
    "        return dc_comp\n",
    "    \n",
    "    #pseudo-amino acid composition\n",
    "    \n",
    "    def pseaac_composition(seq,path):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "        r.pkgTest(\"base\")\n",
    "        r.pkgTest(\"protr\")\n",
    "    #r.source(\"SVM_prediction.R\") #calling R script to get prediction results from SVM\n",
    "    #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "    #r.pkgTest_decipher(\"DECIPHER\")\n",
    "        r.source(\"PAAC_BAC.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        pseaac_comp = r.extractPAAC_BAC(seq,path)\n",
    "        return pseaac_comp\n",
    "    \n",
    "    #amphiphilic pseudo-amino acid composition\n",
    "    \n",
    "    def apseaac_composition(seq,path):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "        r.pkgTest(\"base\")\n",
    "        r.pkgTest(\"protr\")\n",
    "    #r.source(\"SVM_prediction.R\") #calling R script to get prediction results from SVM\n",
    "    #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "    #r.pkgTest_decipher(\"DECIPHER\")\n",
    "        r.source(\"APAAC_BAC.R\") #calling R script to compute amino acid composition\n",
    "  \n",
    "        apseaac_comp = r.extractAPAAC_BAC(seq,path)\n",
    "        return apseaac_comp\n",
    "    \n",
    "    #composition for CTD model \n",
    "    \n",
    "    def ctd_composition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"CTDC.R\") #calling R script to compute composition for CTD model\n",
    "  \n",
    "        ctd_comp = r.extractCTDC_BAC(seq)\n",
    "        return ctd_comp\n",
    "    \n",
    "    \n",
    "    #transition for CTD model\n",
    "    \n",
    "    def ctd_transition(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"CTDT.R\") #calling R script to compute transition for CTD model\n",
    "  \n",
    "        ctd_trans = r.extractCTDT_BAC(seq)\n",
    "        return ctd_trans\n",
    "    \n",
    "    \n",
    "    #distribution for CTD model\n",
    "    \n",
    "    def ctd_distribution(seq):\n",
    "        \n",
    "        r=ro.r\n",
    "        r.source(\"CTDD.R\") #calling R script to compute distribution for CTD model\n",
    "  \n",
    "        ctd_distr = r.extractCTDD_BAC(seq)\n",
    "        return ctd_distr\n",
    "    \n",
    "\n",
    "    \n",
    "    #generate secondary structure features\n",
    "        \n",
    "    def secondstruct_feat(seq):\n",
    "        \n",
    "        \n",
    "        base = importr('base')\n",
    "        \n",
    "        r=ro.r\n",
    "        #r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "        #r.pkgTest(\"base\")\n",
    "        \n",
    "        #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "        #r.pkgTest_decipher(\"DECIPHER\")\n",
    "        r.source(\"GL_new.R\") #calling R script to compute secondary structure features\n",
    "  \n",
    "        ss_ft = r.extractSSF(seq)\n",
    "        #print(ssfile)\n",
    "        return ss_ft\n",
    "    \n",
    "    \n",
    "    #####################################################################################\n",
    "    \n",
    "    \n",
    "    aa_dict='ARNDCEQGHILKMFPSTWYV'\n",
    "    \n",
    "    for i in range(1,21):\n",
    "        all_generated_features[\"aac_%s\"%i]=\"\"\n",
    "    \n",
    "    for i in range(1,401):\n",
    "        all_generated_features[\"dipep_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,31):\n",
    "        all_generated_features[\"pseudo_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,41):\n",
    "        all_generated_features[\"amphipseudo_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,22):\n",
    "        all_generated_features[\"comp_%s\"%i]=\"\"\n",
    "    \n",
    "    for i in range(1,22):\n",
    "        all_generated_features[\"tran_%s\"%i]=\"\"\n",
    "        \n",
    "    for i in range(1,106):\n",
    "        all_generated_features[\"dist_%s\"%i]=\"\"\n",
    "    \n",
    "    for i in range(1,7):\n",
    "        all_generated_features[\"ss_%s\"%i]=\"\"\n",
    "    \n",
    "    \n",
    "    # Execute for each sequence\n",
    "    \n",
    "    seqs_length=[]\n",
    "    counter=0\n",
    "    counting_seq=0\n",
    "\n",
    "    for seq in sequences:\n",
    "        seqs_length.append(len(seq))\n",
    "        counter+=1\n",
    "        aa_comp=aa_composition(seq)\n",
    "        dir_path = os.getcwd()\n",
    "        dir_path = dir_path.replace(\"\\\\\", \"/\")\n",
    "        dir_path+=\"/AAidx.csv\"\n",
    "        dc_comp=dc_composition(seq)\n",
    "        pseaac_comp=pseaac_composition(seq,dir_path)\n",
    "        apseaac_comp=apseaac_composition(seq,dir_path)\n",
    "        ctd_comp = ctd_composition(seq)\n",
    "        ctd_trans = ctd_transition(seq)\n",
    "        ctd_distr = ctd_distribution(seq)\n",
    "        ss_struct = secondstruct_feat(seq)\n",
    "        \n",
    "        all_generated_features.at[counting_seq,\"aac_1\":\"aac_20\"]=aa_comp\n",
    "        all_generated_features.at[counting_seq,\"dipep_1\":\"dipep_400\"]=dc_comp\n",
    "        all_generated_features.at[counting_seq,\"pseudo_1\":\"pseudo_30\"]=pseaac_comp\n",
    "        all_generated_features.at[counting_seq,\"amphipseudo_1\":\"amphipseudo_40\"]=apseaac_comp\n",
    "        all_generated_features.at[counting_seq,\"comp_1\":\"comp_21\"]=ctd_comp\n",
    "        all_generated_features.at[counting_seq,\"tran_1\":\"tran_21\"]=ctd_trans\n",
    "        all_generated_features.at[counting_seq,\"dist_1\":\"dist_105\"]=ctd_distr[:105]\n",
    "        all_generated_features.at[counting_seq,\"ss_1\":\"ss_6\"]=ss_struct\n",
    "        \n",
    "        x_len=len(seq)\n",
    "        \n",
    "        #get path for current directiry\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        counting_seq+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "    eliminate= []\n",
    "    \n",
    "    if svalue==0:\n",
    "        #features_selected=[\"S5\", \"D80\", \"C21\", \"S4\", \"T10\", \"D81\"]\n",
    "        features_selected=[\"pseudo_11\",\"pseudo_2\",\"dist_3\",\"dist_76\",\"dist_18\",\"dist_62\",\"dist_93\",\"pseudo_13\",\"dist_75\",\"pseudo_14\",\"pseudo_4\",\n",
    "\"pseudo_15\",\"pseudo_6\",\"pseudo_20\",\"dist_47\",\"dist_17\",\"pseudo_1\",\"dist_77\",\"pseudo_10\",\"dist_91\",\"pseudo_16\",\"pseudo_9\",\n",
    "\"dist_16\",\"dist_2\",\"pseudo_17\",\"dist_72\",\"pseudo_7\",\"dist_78\",\"dist_1\",\"pseudo_19\",\"comp_16\",\"ss_1\",\"dist_26\",\"ss_3\",\n",
    "\"tran_18\",\"dist_29\",\"pseudo_8\",\"dist_69\",\"aac_8\",\"dist_23\",\"pseudo_3\",\"comp_15\",\"dist_7\",\"dist_20\",\"pseudo_12\",\"dist_10\",\n",
    "\"comp_4\",\"dist_70\",\"comp_5\",\"dist_58\",\"comp_18\",\"dist_4\",\"comp_2\",\"dist_21\",\"dist_56\",\"ss_2\",\"comp_10\",\"dist_96\",\"dist_105\",\n",
    "\"dist_90\",\"dist_44\",\"dist_53\",\"tran_6\",\"dist_85\",\"pseudo_18\",\"dist_63\",\"dist_67\",\"dist_50\",\"dist_102\",\"dist_13\",\"dist_79\",\n",
    "\"dist_61\",\"dist_82\",\"comp_17\",\"dist_59\",\"comp_11\",\"dist_97\",\"dist_64\",\"dist_14\",\"dist_87\",\"dist_99\",\"ss_6\",\"dist_73\",\n",
    "\"tran_16\",\"dist_88\",\"dist_34\",\"dist_24\",\"dist_94\",\"tran_17\",\"dist_6\",\"dist_28\",\"dist_27\",\"dist_68\",\"dist_84\",\"comp_1\",\n",
    "\"tran_2\",\"pseudo_5\",\"tran_3\",\"tran_10\",\"tran_21\",\"comp_3\",\"tran_20\",\"dist_81\",\"dist_15\",\"tran_19\",\"ss_4\",\"dist_89\",\n",
    "\"dist_19\",\"dist_100\",\"comp_6\",\"tran_1\",\"dist_38\",\"dist_103\",\"aac_1\",\"dist_71\",\"dist_8\",\"dist_22\",\"tran_5\",\"comp_13\",\n",
    "\"comp_19\",\"dist_83\",\"dist_66\",\"dist_30\",\"dist_37\",\"dist_49\",\"dist_52\",\"dist_55\",\"dist_5\",\"dist_40\",\"dist_65\",\"dist_9\"]\n",
    "        \n",
    "    for i in range(1,21):\n",
    "        a=\"aac_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "            \n",
    "    for i in range(1,401):\n",
    "        a=\"dipep_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    for i in range(1,31):\n",
    "        a=\"pseudo_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)        \n",
    "    \n",
    "    for i in range(1,41):\n",
    "        a=\"amphipseudo_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    for i in range(1,22):\n",
    "        a=\"comp_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "            \n",
    "    for i in range(1,22):\n",
    "        a=\"tran_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    for i in range(1,106):\n",
    "        a=\"dist_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)  \n",
    "    \n",
    "            \n",
    "    for i in range(1,7):\n",
    "        a=\"ss_%s\"%i\n",
    "        if a not in features_selected:\n",
    "            eliminate.append(a)\n",
    "    \n",
    "    all_generated_features=all_generated_features.drop(eliminate, axis=1)\n",
    "    \n",
    "    if svalue==0:\n",
    "        #all_generated_features=all_generated_features[['S5', 'D80', 'C21', 'S4', 'T10', 'D81']]\n",
    "        all_generated_features=all_generated_features[[\"pseudo_11\",\"pseudo_2\",\"dist_3\",\"dist_76\",\"dist_18\",\"dist_62\",\"dist_93\",\"pseudo_13\",\"dist_75\",\"pseudo_14\",\"pseudo_4\",\n",
    "\"pseudo_15\",\"pseudo_6\",\"pseudo_20\",\"dist_47\",\"dist_17\",\"pseudo_1\",\"dist_77\",\"pseudo_10\",\"dist_91\",\"pseudo_16\",\"pseudo_9\",\n",
    "\"dist_16\",\"dist_2\",\"pseudo_17\",\"dist_72\",\"pseudo_7\",\"dist_78\",\"dist_1\",\"pseudo_19\",\"comp_16\",\"ss_1\",\"dist_26\",\"ss_3\",\n",
    "\"tran_18\",\"dist_29\",\"pseudo_8\",\"dist_69\",\"aac_8\",\"dist_23\",\"pseudo_3\",\"comp_15\",\"dist_7\",\"dist_20\",\"pseudo_12\",\"dist_10\",\n",
    "\"comp_4\",\"dist_70\",\"comp_5\",\"dist_58\",\"comp_18\",\"dist_4\",\"comp_2\",\"dist_21\",\"dist_56\",\"ss_2\",\"comp_10\",\"dist_96\",\"dist_105\",\n",
    "\"dist_90\",\"dist_44\",\"dist_53\",\"tran_6\",\"dist_85\",\"pseudo_18\",\"dist_63\",\"dist_67\",\"dist_50\",\"dist_102\",\"dist_13\",\"dist_79\",\n",
    "\"dist_61\",\"dist_82\",\"comp_17\",\"dist_59\",\"comp_11\",\"dist_97\",\"dist_64\",\"dist_14\",\"dist_87\",\"dist_99\",\"ss_6\",\"dist_73\",\n",
    "\"tran_16\",\"dist_88\",\"dist_34\",\"dist_24\",\"dist_94\",\"tran_17\",\"dist_6\",\"dist_28\",\"dist_27\",\"dist_68\",\"dist_84\",\"comp_1\",\n",
    "\"tran_2\",\"pseudo_5\",\"tran_3\",\"tran_10\",\"tran_21\",\"comp_3\",\"tran_20\",\"dist_81\",\"dist_15\",\"tran_19\",\"ss_4\",\"dist_89\",\n",
    "\"dist_19\",\"dist_100\",\"comp_6\",\"tran_1\",\"dist_38\",\"dist_103\",\"aac_1\",\"dist_71\",\"dist_8\",\"dist_22\",\"tran_5\",\"comp_13\",\n",
    "\"comp_19\",\"dist_83\",\"dist_66\",\"dist_30\",\"dist_37\",\"dist_49\",\"dist_52\",\"dist_55\",\"dist_5\",\"dist_40\",\"dist_65\",\"dist_9\"]]\n",
    "    \n",
    "    all_generated_features.to_csv(\"%s.csv\" %file_name, header=True, index=False)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#predicting antiviral peptide sequences\n",
    "def predict_BAC_sequences(svalue):\n",
    "    Delete()\n",
    "    #reading training and test datsets \n",
    "    \n",
    "    dir_path = os.getcwd()\n",
    "    dir_path = dir_path.replace(\"\\\\\", \"/\")\n",
    "    if svalue==0:\n",
    "        training_file_path=dir_path + \"/ML-selected_training_merged_file.csv\" #path for aac training set\n",
    "    \n",
    "    \n",
    "    testing_file_path=dir_path + \"/input_seq.csv\" #path for input sequences\n",
    "    \n",
    "    #print(training_file_path)\n",
    "    #print(testing_file_path)\n",
    "    \n",
    "    #base = importr('base')\n",
    "    #utils = rpackages.importr('utils')\n",
    "    #utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
    "    #packnames = ('ROSE', 'e1071', 'caret') \n",
    "    #utils.install_packages(StrVector(packnames))\n",
    "    r=ro.r\n",
    "    r.source(\"file_with_pkgTest.R\") #check whether required R package is installed\n",
    "    #r.pkgTest(\"ROSE\")\n",
    "    r.pkgTest(\"base\")\n",
    "    r.pkgTest(\"e1071\") #install e1071 R package if not installed\n",
    "    r.pkgTest(\"caret\")\n",
    "    \n",
    "    #r.pkgTest(\"protr\")\n",
    "    #r.source(\"SVM_prediction.R\") #calling R script to get prediction results from SVM\n",
    "    #r.source(\"file_with_pkgTest_decipher.R\")\n",
    "    #r.pkgTest_decipher(\"DECIPHER\")\n",
    "    r.source(\"SVM_classifier_BAC_new.R\") #calling R script to get prediction results from SVM\n",
    "    predictions = r.predict_results(training_file_path,testing_file_path)\n",
    "    #print(predictions)\n",
    "    #print(predictions[1])\n",
    "    \n",
    "    \n",
    "    # #################################################################\n",
    "    lines = [line.rstrip('\\n') for line in open('input_seq.fasta')]\n",
    "    #print(lines)\n",
    "\n",
    "    #reading all sequences in sequences and their names in sequences_name\n",
    "    save_sequences= ''\n",
    "    sequences_input= []\n",
    "    sequences_name_input= []\n",
    "\n",
    "\n",
    "    for l in lines:\n",
    "        if(l == \"\"): #blank lines are disregarded\n",
    "                pass\n",
    "        elif (l[0] == '>'):\n",
    "            sequences_name_input.append(l[1:])\n",
    "            sequences_input.append(save_sequences)\n",
    "            save_sequences= ''\n",
    "        else:\n",
    "            save_sequences+= l\n",
    "\n",
    "    sequences_input.append(save_sequences)\n",
    "    del sequences_input[0]\n",
    "    \n",
    "   \n",
    "    \n",
    " \n",
    "   #generate prediction statistics\n",
    "\n",
    "    predict_file = open(\"predicted_bacteriocin_sequences.fasta\", \"w+\")\n",
    "\n",
    "    count_resistance_sequences=0   \n",
    "    for i in range(len(predictions)):\n",
    "        if (predictions[i]==1 ):\n",
    "            predict_file.write(str(sequences_name_input[i])+ '\\n'+ '\\n')\n",
    "            count_resistance_sequences+=1\n",
    "    predict_file.close()\n",
    "    del predict_file\n",
    "\n",
    "\n",
    "    one_line=\"Total number of predicted bacteriocin sequences = \"+str(count_resistance_sequences) + \"\\n\"  +\"\\n\" \n",
    "    with open(\"predicted_bacteriocin_sequences.fasta\", 'r+') as fp:\n",
    "        lines = fp.readlines()     \n",
    "        lines.insert(0, one_line)  \n",
    "        fp.seek(0)                 \n",
    "        fp.writelines(lines)  \n",
    "        \n",
    "     #prediction probability\n",
    "     #r.source(\"svm_with_percent_identity.R\") #calling R script to get prediction results from SVM\n",
    "     #predictionsR = r.predict_resultsP(training_file_path,testing_file_path)\n",
    "    r.source(\"svm_with_percent_identity.R\") #calling R script to get prediction results from SVM\n",
    "    predictionsR = r.predict_resultsP(training_file_path,testing_file_path)\n",
    "    #df = pd.read_csv(predictionsR) \n",
    "    prob_values=pd.DataFrame(predictionsR)  \n",
    "    row = prob_values.transpose()\n",
    "    #print(row)\n",
    "    row=row.rename(columns={ 0: \"Positive\", 1: \"Negative\"})\n",
    "    #print(row)\n",
    "    #print(sequences_name_input)\n",
    "    df = pd.DataFrame(sequences_name_input)\n",
    "    df=df.rename(columns={ 0: \"NCBI no\"})\n",
    "    #print(df)\n",
    "    concatenated_df =pd.concat([df, row], axis=1, join=\"inner\")\n",
    "    #print(concatenated_df)\n",
    "    #concatenated_df = concatenated_df.rename(columns={ 0: \"NCBI\", '0': \"Positive\", 1: \"Negative\"})\n",
    "    #print(concatenated_df)\n",
    "\n",
    "    concatenated_df.to_csv('probability_results.csv', header=True, index=False)\n",
    "\n",
    "\n",
    "\n",
    "#include new sequences to the training and test datasets \n",
    "\n",
    "def add_new_sequences(svalue,sgval): \n",
    "    file_new = open(\"input_seq.fasta\", \"r\")\n",
    "    #data_new = file_new.read()\n",
    "    file_new.close()\n",
    "    \n",
    "    \n",
    "        \n",
    "    feature_extraction('input_seq',svalue)\n",
    "    df1 = pd.read_csv('input_seq.csv')\n",
    "    if sgval==1:\n",
    "        Otpt = [1] * df1.shape[0]\n",
    "    else:\n",
    "        Otpt = [-1] * df1.shape[0]\n",
    "    df1[\"Output\"]= Otpt\n",
    "    df1.to_csv(\"seq_excld_header.csv\", header=False, index=False)\n",
    "    file_new_features = open(\"seq_excld_header.csv\", \"r\")\n",
    "    data_new_features = file_new_features.read()\n",
    "    file_new_features.close()\n",
    "    \n",
    "    if svalue==0:\n",
    "        file_all_features= open(\"ML-selected_training_merged_file.csv\",\"a\")\n",
    "    \n",
    "    \n",
    "    file_all_features.write(data_new_features)\n",
    "    file_all_features.close()\n",
    "\n",
    "    # reset training and test data sets\n",
    "def restore_training_data():\n",
    "    \n",
    "    copyfile(\"ML-selected_training_merged_file_actual.csv\", \"ML-selected_training_merged_file.csv\")\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "#build graphical user interface\n",
    "\n",
    "root = tkinter.Tk()\n",
    "root.title(\"BaPreS\")\n",
    "root.geometry(\"530x570\")\n",
    "#520x485\n",
    "root.configure(background=\"Light blue\")\n",
    "#root.wm_attributes('-alpha', 0.7)\n",
    "#peach puff\n",
    "\n",
    "#canvas = Canvas(root, width=235, height = 139)  \n",
    "#canvas = Canvas(root, width=159, height = 173, bg='Light blue',highlightthickness=0)\n",
    "canvas = Canvas(root, width=50, height = 5, bg='Light blue',highlightthickness=0)\n",
    "#canvas = Canvas(root, width=362, height = 352, bg='white smoke',highlightthickness=0)\n",
    "#canvas.pack(padx=1, pady=1)\n",
    "#canvas.pack(padx=1, pady=1)\n",
    "\n",
    "# Create label\n",
    "l = Label(root, text = \"BaPreS: A Software Tool for Predicting \\n Bacteriocin Protein Sequences\")\n",
    "l.config(font =(\"Courier\", 14))\n",
    "l.pack(padx=5, pady=5)\n",
    "\n",
    "#T = Text(root, font=\"none 12 bold\",bd=0,height=2, width=37, padx=0, pady=0)\n",
    "\n",
    "\n",
    "#T.pack(padx=0, pady=0)\n",
    "\n",
    "\n",
    "#T.insert(END, \"      BacPred: A Software Tool for Predicting \\n                Bacteriocin Peptide Sequence\",\"center\")\n",
    "\n",
    "#for file upload\n",
    "\n",
    "\n",
    "def openFile():\n",
    "    filepath = filedialog.askopenfilename(initialdir=\"C:\\\\Users\\\\Cakow\\\\PycharmProjects\\\\Main\",\n",
    "                                          title=\"Open Input Sequence File?\",\n",
    "                                          filetypes= ((\"fasta files\",\"*.fasta\"),\n",
    "                                          (\"all files\",\"*.*\")))\n",
    "    \n",
    "    #print(filepath)\n",
    "    filepath = open(filepath,'r')\n",
    "    content= filepath.read()\n",
    "    my_text.insert(END,content)\n",
    "    saveFile()\n",
    "    filepath.close()\n",
    "    \n",
    "#end file upload and save\n",
    "\n",
    "#file save \n",
    "def saveFile():\n",
    "    text_file=open('input_seq.fasta','w')\n",
    "    text_file.write(my_text.get(1.0,END))\n",
    "    my_text.delete('1.0', END)\n",
    "\n",
    "\n",
    "#end file save\n",
    "\n",
    "def Delete():\n",
    "    text_read.delete('1.0', END)\n",
    "    \n",
    "def predictResult():\n",
    "    Delete()\n",
    "    #filepath = filedialog.askopenfilename(initialdir=\"predicted_AVP_sequences.fasta\")\n",
    "    filepath = open(\"predicted_bacteriocin_sequences.fasta\",'r')\n",
    "    content= filepath.read()\n",
    "    text_read.insert(END,content)\n",
    "    filepath.close()\n",
    "    \n",
    "def predictProbabiliteResult():    \n",
    "    Delete()\n",
    "    df = pd.read_csv('probability_results.csv')\n",
    "    #filepath = open(\"probability_results.csv\",'r')\n",
    "    #content= filepath.read()\n",
    "    #table = df.to_markdown(tablefmt=\"pipe\", index=False)\n",
    "    table = df.to_string(index=False, float_format='%.4f', justify='center')\n",
    "    content=table\n",
    "    text_read.insert(END,content)\n",
    "    \n",
    "\n",
    "    \n",
    "def setup_window(soption):\n",
    "    window = Toplevel(root)\n",
    "    window.geometry(\"320x60\")\n",
    "    window.configure(background=\"tan\")\n",
    "    if soption not in choices:\n",
    "        Lbl = Label(window, bg=\"tan\",fg=\"black\",text=\"Please Select an Option\")\n",
    "        Lbl.config(font=('Helvetica', 8, 'bold'))\n",
    "        Lbl.pack( )\n",
    "    else:\n",
    "        Lbl = Label(window, bg=\"tan\",fg=\"black\",text=\"Done!\")\n",
    "        Lbl.config(font=('Helvetica', 8, 'bold'))\n",
    "        Lbl.pack( )\n",
    "    \n",
    "    Btn=Button(window, text=\"OK\", command=window.destroy) \n",
    "    Btn.config(font=('Helvetica', 8, 'bold'))\n",
    "    Btn.pack()\n",
    "  \n",
    "\n",
    "    \n",
    "#peform operation based on choice    \n",
    "def Send():\n",
    "   \n",
    "    sf = \"%s\" % var.get()\n",
    "    if var.get()==choices[0]:\n",
    "        op_value=0\n",
    "        feature_extraction('input_seq',op_value)\n",
    "        predict_BAC_sequences(op_value)\n",
    "        \n",
    "    \n",
    "    elif var.get()==choices[1]:\n",
    "        op_value=0\n",
    "        signvalue=1\n",
    "        add_new_sequences(op_value,signvalue)\n",
    "    \n",
    "    elif var.get()==choices[2]:\n",
    "        op_value=0\n",
    "        signvalue=-1\n",
    "        add_new_sequences(op_value,signvalue)\n",
    "    \n",
    "    \n",
    "    elif var.get()==choices[3]:\n",
    "        restore_training_data()\n",
    "    \n",
    "    \n",
    "    setup_window(sf)\n",
    "   \n",
    "    \n",
    "#file open \n",
    "button = Button(text=\"Open and Save Input Sequences\",command=openFile)\n",
    "button.config(font=('Helvetica', 8, 'bold'))\n",
    "button.pack(padx=10, pady=10)\n",
    "\n",
    "\n",
    "\n",
    "#data save\n",
    "#button = Button(text='Save',command=saveFile)\n",
    "#button.config(font=('Helvetica', 8, 'bold'))\n",
    "#button.pack(padx=10, pady=10)\n",
    "#data save eb=nd\n",
    "\n",
    "var = tkinter.StringVar(root)\n",
    "# initial value\n",
    "var.set('< Please Select Option >')\n",
    "choices = ['Predict Bacteriocin Sequences', \\\n",
    "           'Add New  Bacteriocin Sequences',  \\\n",
    "           \n",
    "           'Add New Non-bacteriocin Sequences',  \\\n",
    "           \n",
    "           'Restore Training Set']\n",
    "option = tkinter.OptionMenu(root, var, *choices)\n",
    "#option.config(bg = \"GREEN\")\n",
    "#helv35=font.Font(family='Helvetica', size=36)\n",
    "option.config(font=('Helvetica', 8, 'bold')) \n",
    "#option[\"menu\"].config(bg=\"GREEN\")\n",
    "option[\"menu\"].config(font=('Helvetica', 8, 'bold'))\n",
    "option.pack( padx=10, pady=40)\n",
    "button = tkinter.Button(root, text=\"Submit\", command=Send)\n",
    "button.config(font=('Helvetica', 8, 'bold'))\n",
    "button.pack(padx=10, pady=10)\n",
    "\n",
    "\n",
    "#text box for file save data\n",
    "\n",
    "frame = Frame(root)\n",
    "text_read=Text(\n",
    "    frame,\n",
    "    font=(\"Helvetical\",8),\n",
    "    height=15,\n",
    "    width=45,\n",
    "    wrap='word',\n",
    ")\n",
    "text_read.pack(side=LEFT,expand=True)\n",
    "\n",
    "button1 = tkinter.Button(text='Prediction Result',command=predictResult)\n",
    "\n",
    "\n",
    "button1.config(font=('Helvetica', 8, 'bold'))\n",
    "button1.pack(side=tkinter.LEFT, padx=5, pady=5)\n",
    "\n",
    "button2 = tkinter.Button(text='Probability Result',command=predictProbabiliteResult)\n",
    "button2.config(font=('Helvetica', 8, 'bold'))\n",
    "button2.pack(side=tkinter.RIGHT, padx=5, pady=5)\n",
    "\n",
    "#button2 = tkinter.Button(text='Detele Text Data',command=Delete)\n",
    "#button2.config(font=('Helvetica', 8, 'bold'))\n",
    "#button2.pack(side=tkinter.RIGHT, padx=10, pady=10)\n",
    "\n",
    "sb = Scrollbar(frame)\n",
    "sb.pack(side=RIGHT, fill=BOTH)\n",
    "\n",
    "text_read.config(yscrollcommand=sb.set)\n",
    "sb.config(command=text_read.yview)\n",
    "\n",
    "frame.pack(expand=True)\n",
    "\n",
    "\n",
    "\n",
    "my_text = Text(\n",
    "    #frame,\n",
    "    #wrap='word',\n",
    "    font=(\"Helvetical\",8)\n",
    ")\n",
    "\n",
    "#my_text.pack(side=LEFT,expand=True)\n",
    "my_text.pack_forget()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#my_text = Text(root, width=50, height=5, font=(\"Helvetical\",8))\n",
    "#my_text.pack()\n",
    "\n",
    "\n",
    "#end saved opened file\n",
    "\n",
    "# Python program to create\n",
    "# a file explorer in Tkinter\n",
    "\n",
    "# import all components\n",
    "# from the tkinter library\n",
    "#from tkinter import *\n",
    "\n",
    "# import filedialog module\n",
    "#from tkinter import filedialog\n",
    "\n",
    "# Function for opening the\n",
    "# file explorer window\n",
    "#data save\n",
    "\n",
    "\n",
    "\n",
    "root.mainloop()\n",
    "#end_time=time.time()\n",
    "#print(\"--- %s seconds ---\" % (end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
